{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Flood Impact Assessment using Sentinel 1 data\n",
    "\n",
    "* **Products used:** \n",
    "[s1_rtc](https://explorer.digitalearth.africa/products/s1_rtc), [esa_worldcover](https://explorer.digitalearth.africa/products/esa_worldcover), [dem_srtm](https://explorer.digitalearth.africa/products/dem_srtm),"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "**Keywords** :index:`data used; sentinel-1`,:index:`datasets; sentinel-1`, index:`SAR`, :index:`data used; ESA WorldCover`, :index:`datasets; esa_worldcover`, :index: 'data used; Copernicus DEM 30 m', :index: 'datasets; dem_cop_30', :index:`urban`, :index:`analysis;"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Theoretical basis\n",
    "\n",
    "- Water has low backscatter, and it appears as dark tones compared to other land cover classes. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Description\n",
    "\n",
    "This notebook uses k-means clustering to classify land as 'urban' then compares those results with the ESA WorldCover global land cover product for the year 2020.\n",
    "\n",
    "The choice of the number of clusters to use for the k-means clustering and the pixel value that represents the urban land cover class can be informed by comparing the prediction images with the \"ground truth\" dataset.\n",
    "\n",
    "This notebook contains the following steps:\n",
    "\n",
    "1. Select a location and time range  for the analysis.\n",
    "2. Load Sentinel-1 backscatter data for the area of interest. \n",
    "3. Convert the digital numbers to dB values for analysis.\n",
    "4. Generate a median VH and VV polarization composite image from the Sentinel 1 data.\n",
    "5. Perform k-means clustering on the median composite image. \n",
    "6. Show the k-means clustering urbanization prediction image.\n",
    "7. Load and show the \"ground truth\" ESA Worldcover data for the year 2020.\n",
    "8. Compare the urbanization prediction with the \"ground truth\" data visually and statistically.\n",
    "9. Water Change detection.\n",
    "10.Extraction of the flooded areas.\n",
    "11.DEM generation\n",
    "12.Vulnerability Map."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "\n",
    "To run this analysis, run all the cells in the notebook, starting with the \"Load packages\" cell. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If packages are not available install them in terminal using package installer \n",
    "\n",
    "pip install datacube==1.6.2\n",
    "\n",
    "Still this is not working on my local machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages\n",
    "Import the Python packages that are used for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datacube'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-081eb76ea65e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdatacube\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolors\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmcolours\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'datacube'"
     ]
    }
   ],
   "source": [
    "# Load the necessary Python packages.\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "\n",
    "import datacube\n",
    "import matplotlib.colors as mcolours\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from deafrica_tools.classification import sklearn_flatten, sklearn_unflatten\n",
    "from deafrica_tools.dask import create_local_dask_cluster\n",
    "from deafrica_tools.datahandling import load_ard\n",
    "from deafrica_tools.plotting import display_map, plot_lulc\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from deafrica_tools.plotting import rgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up a Dask cluster\n",
    "\n",
    "Dask can be used to better manage memory use down and conduct the analysis in parallel. \n",
    "For an introduction to using Dask with Digital Earth Africa, see the [Dask notebook](../Beginners_guide/08_Parallel_processing_with_dask.ipynb).\n",
    "\n",
    ">**Note**: We recommend opening the Dask processing window to view the different computations that are being executed; to do this, see the *Dask dashboard in DE Africa* section of the [Dask notebook](../Beginners_guide/08_parallel_processing_with_dask.ipynb).\n",
    "\n",
    "To use Dask, set up the local computing cluster using the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_local_dask_cluster()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the datacube\n",
    "\n",
    "Connect to the datacube so we can access the Digital Earth Africa data.\n",
    "The `app` parameter is a unique name for the analysis which is based on the notebook file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = datacube.Datacube(app=\"Urban_area_mapping\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis parameters\n",
    "\n",
    "The following cell sets the parameters, which define the area of interest and the length of time to conduct the analysis.\n",
    "The parameters are:\n",
    "* `central_lat`: The central latitude of the area of interest to analyse.\n",
    "* `central_lon`: The central longitude of the area of interest to analyse.\n",
    "* `buffer`: The number of square degrees to load around the central latitude and longitude. \n",
    "For reasonable loading times, set this as `0.1` or lower.\n",
    "* `time_range`: The time range for your analysis, e.g.`('2020')` if you wanted data from all of the year 2020.\n",
    "\n",
    "**If running the notebook for the first time**, keep the default settings below.\n",
    "This will demonstrate how the analysis works and provide meaningful results.\n",
    "The example covers part of  Nairobi County, Kenya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the area of interest.\n",
    "central_lat = 7.77804\n",
    "central_lon = 6.73376\n",
    "lat_buffer = 0.05\n",
    "lon_buffer = 0.05\n",
    "\n",
    "# Combine lat, lon with their respective buffers to get area of interest.\n",
    "lat_range = (central_lat - lat_buffer, central_lat + lat_buffer)\n",
    "lon_range = (central_lon - lon_buffer, central_lon + lon_buffer)\n",
    "\n",
    "# Time frame for the analysis.\n",
    "time_range = (\"2021-07\", \"2021-09\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the selected location\n",
    "\n",
    "The next cell will display the selected area on an interactive map.\n",
    "Feel free to zoom in and out to get a better understanding of the area you'll be analysing.\n",
    "Clicking on any point of the map will reveal the latitude and longitude coordinates of that point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# View the study area\n",
    "display_map(x=lon_range, y=lat_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and view the Sentinel-1 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create a datacube query object\n",
    "We will create a dictionary that will contain the parameters that will be used to load the Sentinel 1 data from the Digital Earth Africa datacube."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = {\n",
    "    \"y\": lat_range,\n",
    "    \"x\": lon_range,\n",
    "    \"time\": time_range,\n",
    "    \"output_crs\": \"EPSG:32632\",\n",
    "    \"resolution\": (-20, 20),\n",
    "    \"dask_chunks\": dict(x=1000, y=1000),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Sentinel 1 data\n",
    "The first step in the analysis is to load Sentinel-1 backscatter data for the specified area of interest.\n",
    "This uses the pre-defined [load_ard](../Frequently_used_code/Using_load_ard.ipynb) utility function. \n",
    "The `load_ard` function is used here to load an analysis ready dataset free of shadow, and missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_origin = load_ard(\n",
    "    dc=dc, products=[\"s1_rtc\"], \n",
    "    measurements=[\"vv\", \"vh\"], \n",
    "    group_by=\"solar_day\",\n",
    "    sat_orbit_state= 'ascending',\n",
    "    **query\n",
    ")\n",
    "\n",
    "ds_origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage.filters import uniform_filter\n",
    "from scipy.ndimage.measurements import variance\n",
    "from skimage.filters import threshold_minimum\n",
    "\n",
    "\n",
    "def lee_filter(da, size):\n",
    "    \"\"\"\n",
    "    Apply lee filter of specified window size.\n",
    "    Adapted from https://stackoverflow.com/questions/39785970/speckle-lee-filter-in-python\n",
    "\n",
    "    \"\"\"\n",
    "    img = da.values\n",
    "    img_mean = uniform_filter(img, (size, size))\n",
    "    img_sqr_mean = uniform_filter(img**2, (size, size))\n",
    "    img_variance = img_sqr_mean - img_mean**2\n",
    "\n",
    "    overall_variance = variance(img)\n",
    "\n",
    "    img_weights = img_variance / (img_variance + overall_variance)\n",
    "    img_output = img_mean + img_weights * (img - img_mean)\n",
    "    \n",
    "    return img_output\n",
    "\n",
    "valid = xr.ufuncs.isfinite(ds_origin)\n",
    "ds_origin = ds_origin.where(valid, 0)\n",
    "\n",
    "# Create a new entry in dataset corresponding to filtered VV and VH data\n",
    "ds_origin[\"filtered_vv\"] = ds_origin.vv.groupby(\"time\").apply(lee_filter, size=5)\n",
    "ds_origin[\"filtered_vh\"] = ds_origin.vh.groupby(\"time\").apply(lee_filter, size=5)\n",
    "\n",
    "# Null pixels should remain null\n",
    "ds_origin['filtered_vv'] = ds_origin.filtered_vv.where(valid.vv)\n",
    "ds_origin['filtered_vh'] = ds_origin.filtered_vh.where(valid.vh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Convert the Digital Number (DN) values to Decibel values (dB)\n",
    "\n",
    "The Sentinel-1 backscatter data is provided as digital number (DN), which can be converted to backscatter in decibel unit (dB) using the function:\n",
    "\n",
    "\\begin{equation}\n",
    "10 * \\log_{10}\\left(\\text{DN} \\right)\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "It is often useful to convert the backscatter to decible (dB) for analysis because the backscatter in dB unit has a more symmetric noise profile and less skewed value distribution for easier statistical evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DN to db values.\n",
    "ds_origin[\"vv\"] = 10 * xr.ufuncs.log10(ds_origin.filtered_vv)\n",
    "ds_origin[\"vh\"] = 10 * xr.ufuncs.log10(ds_origin.filtered_vh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the Sentinel 1 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the first VH and VV observation for the year 2021.\n",
    "fig, ax = plt.subplots(1, 2, figsize=(14, 6), sharey=True)\n",
    "ds_origin.vh.isel(time=0).plot.imshow(cmap=\"Greys_r\", robust=True, ax=ax[0])\n",
    "ds_origin.vv.isel(time=0).plot.imshow(cmap=\"Greys_r\", robust=True, ax=ax[1])\n",
    "ax[0].set_title(\"VH (db)\")\n",
    "ax[1].set_title(\"VV (db)\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_origin.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_selected = ds_origin.isel(time=[0, 6])\n",
    "ds_selected = ds_selected.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_selected.vv.plot(cmap=\"Greys_r\", col='time', size=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_selected.vh.plot(cmap=\"Greys_r\", col='time', size=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_selected['vh/vv'] = ds_selected.vh/ds_selected.vv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting an RGB image for selected timesteps\n",
    "rgb(ds_selected[['vv','vh','vh/vv']], bands=['vv',\n",
    "    'vh', 'vh/vv'], index=[0, 1], size=6);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Selection of SAR polarization\n",
    "SAR polarization is a key factor in flood detection. HH-polarized images are more adequate for flood detection than VV- or crosspolarized images (Baghdadi, et al., 2001; Henry, et al., 2006). HH-polarization gives the highest distinction in backscatter values between dry and wet forested areas (Henry et al., 2006; Jüssi, 2015). For this pratical exercice the available image during the flood had an Intensity VV and VH polarization. The VV polarization was preferred because the medium incident angle of the data makes this image suitable for flood monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 3))\n",
    "ds_selected.isel(time=0).vv.plot.hist(bins=1000, label=\"Pre-flood\")\n",
    "ds_selected.isel(time=1).vv.plot.hist(bins=1000, label=\"Post-flood\", alpha=0.5)\n",
    "plt.xlim(-40, 10)\n",
    "plt.legend()\n",
    "plt.xlabel(\"Backscatter values in (dB)\")\n",
    "plt.title(\"Backscatter distributions of the pre- and post-flood (VV) images\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold determination\n",
    "To separate water from non-water a threshold can be selected. The histogram above shows peaks of different magnitude. Low values of the backscatter will correspond to the water, and high values will correspond to the non-water class. We need to select the value that will separate water from non-water. This value corresponds in our case to the threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import threshold_minimum\n",
    "\n",
    "threshold_vv = threshold_minimum(ds_selected.vv.values)\n",
    "\n",
    "print(threshold_vv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Water / non Water Seperation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_selected_water = ds_selected.vv < threshold_vv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_july = ds_selected_water.where(ds_selected_water==True, 0).isel(time=0)\n",
    "ds_september = ds_selected_water.where(ds_selected_water==True, 0).isel(time=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(14, 6), sharey=True)\n",
    "ds_july.plot(cmap='Blues',  robust=True, ax=ax[0], add_colorbar=False)\n",
    "ds_september.plot(cmap='Reds',  robust=True, ax=ax[1], add_colorbar=False)\n",
    "ax[0].set_title(\"Water Extent in July\")\n",
    "ax[1].set_title(\"Water Extent in September\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Water Change Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change =   ds_september - ds_july"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "water_appeared = change.where(change == 1)\n",
    "permanent_water = change.where((change == 0) & (ds_july > 0))\n",
    "water_disappeared = change.where(change == -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "water_appeared_color = \"Pink\"\n",
    "water_disappeared_color = \"Yellow\"\n",
    "stable_color = \"Blue\"\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "\n",
    "\n",
    "permanent_water.plot.imshow(\n",
    "    cmap=ListedColormap([stable_color]),\n",
    "    add_colorbar=False,\n",
    "    add_labels=False,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "water_appeared.plot.imshow(\n",
    "    cmap=ListedColormap([water_appeared_color]),\n",
    "    add_colorbar=False,\n",
    "    add_labels=False,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "water_disappeared.plot.imshow(\n",
    "    cmap=ListedColormap([water_disappeared_color]),\n",
    "    add_colorbar=False,\n",
    "    add_labels=False,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "plt.legend(\n",
    "    [\n",
    "        Patch(facecolor=stable_color),\n",
    "        Patch(facecolor=water_disappeared_color),\n",
    "        Patch(facecolor=water_appeared_color),\n",
    "    ],\n",
    "    [\n",
    "        f\"Water to Water\",\n",
    "        f\"Water to No Water\",\n",
    "        f\"No Water to Water\",\n",
    "    ],\n",
    "    loc=\"lower left\",\n",
    ")\n",
    "\n",
    "#plt.title(\"Change in water extent: \" + baseline_time + \" to \" + analysis_time);\n",
    "plt.title(\"Change in Water Extent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Land Cover Land Use Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Classification using K-means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-means is an unsupervised classification algorithm, also called clusterization, that groups objects into k groups based on their characteristics. The grouping is done minimizing the sum of the distances between each object and the group or cluster centroid.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell we will create a set of functions which will together be used to perform k-means clustering on our median value composite image. \n",
    "This functions are adapted from the ones used [here](https://ml-gis-service.com/index.php/2020/10/14/data-science-unsupervised-classification-of-satellite-images-with-k-means-algorithm/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defining functions to use for the k-means clustering.\n",
    "def show_clustered(predicted_ds):\n",
    "    \"\"\"\n",
    "    Takes the predicted xarray DataArray and plots it.\n",
    "\n",
    "    Last modified: November 2021\n",
    "    Parameters\n",
    "    ----------\n",
    "    predicted_ds : xarray DataArrray\n",
    "    The xarray DataArray which is the result of the k-means clustering.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    An plot of the predicted_ds.\n",
    "    \"\"\"\n",
    "\n",
    "    # Display predicted_ds Dataset with upto 6 unique classes.\n",
    "    image = predicted_ds\n",
    "\n",
    "    # Color list with 6 colors from the virdis color map.\n",
    "    no_classes = len(np.unique(image))\n",
    "    colour_list = [\"#fde725\", \"#440154\", \"#22a884\", \"#414487\", \"#2a788e\", \"#7ad151\"]\n",
    "    colours = colour_list[:no_classes]\n",
    "    cmap = mcolours.ListedColormap(colours)\n",
    "    bounds = range(0, no_classes + 1)\n",
    "    norm = mcolours.BoundaryNorm(np.array(bounds), cmap.N)\n",
    "    cblabels = [str(i) for i in bounds]\n",
    "    im = image.plot.imshow(cmap=cmap, norm=norm, add_colorbar=True, figsize=(6, 6))\n",
    "    cb = im.colorbar\n",
    "    cb.set_ticks(np.arange(0, no_classes + 1, 1) + 0.5)\n",
    "    cb.set_ticklabels(cblabels)\n",
    "    plt.axis(\"off\")\n",
    "    title = f\"K-means Clustering Predicted Image using {no_classes} clusters\"\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def kmeans_clustering(input_xr, cluster_range):\n",
    "    \"\"\"\n",
    "    Perform sklearn Kmeans clustering on the input Dataset\n",
    "    or Data Array.\n",
    "\n",
    "    Last modified: November 2021\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_xr : xarray.DataArray or xarray.Dataset\n",
    "        Must have dimensions 'x' and 'y', may have dimension 'time'.\n",
    "\n",
    "    cluster_range : list\n",
    "        A list of the number of clusters to use to perform the k-means clustering\n",
    "        on the input_xr Dataset.\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    results : dictionary\n",
    "        A dictionary with the number of clusters as keys and the predicted xarray.DataArrays\n",
    "        as the values. Each predicted xarray.DataArray has the same dimensions 'x', 'y' and\n",
    "        'time' as the input_xr.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Use the sklearn_flatten function to convert the Dataset or DataArray into a 2 dimensional numpy array.\n",
    "    model_input = sklearn_flatten(input_xr)\n",
    "\n",
    "    # Standardize the data.\n",
    "    scaler = StandardScaler()\n",
    "    model_input = scaler.fit_transform(model_input)\n",
    "\n",
    "    # Dictionary to save results\n",
    "    results = {}\n",
    "\n",
    "    # Perform Kmeans clustering on the input dataset for each number of clusters\n",
    "    # in the cluster_range list.\n",
    "    for no_of_clusters in cluster_range:\n",
    "        # Set up the kmeans classification by specifying the number of clusters\n",
    "        # with initialization as k-means++.\n",
    "        km = KMeans(n_clusters=no_of_clusters, init=\"k-means++\", random_state=1)\n",
    "\n",
    "        # Begin iteratively computing the position of the clusters.\n",
    "        km.fit(model_input)\n",
    "\n",
    "        # Use the sklearn kmeans .predict method to assign all the pixels of the\n",
    "        # model input to a unique cluster.\n",
    "        flat_predictions = km.predict(model_input)\n",
    "\n",
    "        # Use the sklearn_unflatten function to convert the flat predictions into a\n",
    "        # xarray DataArray.\n",
    "        predicted = sklearn_unflatten(flat_predictions, input_xr)\n",
    "        predicted = predicted.transpose(\"y\", \"x\")\n",
    "\n",
    "        # Append the results to a dictionary using the number of clusters as the\n",
    "        # column as an key.\n",
    "        results.update({str(no_of_clusters): predicted})\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, we will use a range of clusters to perform  k-means classification on our median composite dataset.\n",
    "\n",
    "Below, **enter the selected polarization to include in the classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = [\"vv\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will run the k-means classification, and then plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "july_urban = ds_selected.isel(time=0)\n",
    "september_urban = ds_selected.isel(time=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "july_urban = july_urban.where(july_urban.apply(np.isfinite)).fillna(0.0)\n",
    "september_urban = september_urban.where(september_urban.apply(np.isfinite)).fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_range = [2, 3, 4]\n",
    "results_july = kmeans_clustering(july_urban[bands], cluster_range)\n",
    "results_september = kmeans_clustering(september_urban[bands], cluster_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot each of the predicted images.\n",
    "for predicted_ds in results_july.values():\n",
    "    show_clustered(predicted_ds)\n",
    "    \n",
    "for predicted_ds in results_september.values():\n",
    "    show_clustered(predicted_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Decide which model and class to assign as 'urban'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### From the plotted predicted images above the best number of clusters to use is `3` clusters. \n",
    "In this image, the most likely pixel value to represent the urban/buit up land cover class is the pixel value `2`. \n",
    "\n",
    "> Note: this may change depending on the area of interest and number of clusters used. In this example, the initial state has been arbitrarily defined using the `random_state` argument in the `kmeans_clustering` function.\n",
    "\n",
    "Set the `key` and the `pixel_value` representing the model and value, respectively, that you want to assign as urban areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask the dataset to retain the pixels which are most likely to be urban/built up.\n",
    "key = \"3\"\n",
    "pixel_value = 2\n",
    "\n",
    "clustering_predicted_ds_july = results_july[key] == pixel_value\n",
    "clustering_predicted_ds_september = results_september[key] == pixel_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_predicted_ds_july.plot.imshow(figsize=(6, 6), add_colorbar=False)\n",
    "plt.title(\"K-means Clustering Predicted image July\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_predicted_ds_september.plot.imshow(figsize=(6, 6), add_colorbar=False)\n",
    "plt.title(\"K-means Clustering Predicted image September\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Validation of the k-means clustering classification\n",
    "We will compare the performance of the urban area k-means clustering classification result against a built area (urban area) map for the study area derived from the ESA World Cover, global 10 m land use/land cover data from 2020. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ESA land use land cover product over the same region as the Sentinel 1 dataset.\n",
    "ds_esa = dc.load(product=\"esa_worldcover\", like=ds_selected.geobox).squeeze()\n",
    "#cci_landcover\n",
    "ds_esa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the ESA land use land cover product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ESA land use land cover product.\n",
    "fig, ax = plt.subplots(figsize=(6, 6), sharey=True)\n",
    "plot_lulc(ds_esa[\"classification\"], product=\"ESA\", legend=True, ax=ax)\n",
    "plt.title(\"ESA WorldCover\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the ESA urban areas alongside the k-means estimate from S1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the built up land cover from the ESA worldcover dataset.\n",
    "esa_urban_class = 50\n",
    "\n",
    "built_up = ds_esa[\"classification\"] == esa_urban_class\n",
    "crop_land = ds_esa[\"classification\"] == 40\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(14, 6), sharey=True)\n",
    "built_up.plot.imshow(ax=ax[0], add_colorbar=False)\n",
    "clustering_predicted_ds_july.plot.imshow(ax=ax[1], add_colorbar=False)\n",
    "ax[1].set_title(\"K-means Clustering Predicted image-July\")\n",
    "ax[0].set_title(\"ESA WorldCover Built up Landcover\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy assessment metrics\n",
    "We will use functions from the `sklearn.metrics` module to evaluate the k-means clustering classification. \n",
    "Accuracy is used when the True Positives and True negatives are more important while F1-score is used when the False Negatives and False Positives are crucial. \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{Overall Accuracy (OA)} = \\frac{\\text{True Positive} + \\text{True Negative}}{\\text{Total Pixels}}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{Producer's Accuracy (PA) or Precision} = \\frac{\\text{True Positive}}{\\text{True Positive} + \\text{False Positive}}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{User's accuracy (UA) or  Recall} = \\frac{\\text{True Positive}}{\\text{True Positive} + \\text{False Negative}}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{F1 Score} = 2*\\frac{\\text{Recall}*\\text{Precision}}{\\text{Recall} + \\text{Precision}}\n",
    "\\end{aligned}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics for the Kmeans Clustering.\n",
    "y_true = sklearn_flatten(built_up)\n",
    "y_pred_kmeans = sklearn_flatten(clustering_predicted_ds_july)\n",
    "\n",
    "# Producer's Accuracies.\n",
    "precision_kmeans = precision_score(y_true, y_pred_kmeans, labels=[0, 1], average=None)\n",
    "urban_precision_kmeans = precision_kmeans[1] * 100\n",
    "\n",
    "# User's Accuracies.\n",
    "recall_kmeans = recall_score(y_true, y_pred_kmeans, labels=[0, 1], average=None)\n",
    "urban_recall_kmeans = recall_kmeans[1] * 100\n",
    "\n",
    "# Overall Accuracy.\n",
    "accuracy_kmeans = accuracy_score(y_true, y_pred_kmeans, normalize=True)\n",
    "overall_accuracy_kmeans = accuracy_kmeans * 100\n",
    "\n",
    "# F1 score.\n",
    "f1score_kmeans = f1_score(y_true, y_pred_kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"\\033[1m\" + \"\\033[91m\" + \"Urban Area Mapping using k-means clustering Results\"\n",
    ")  # bold print and red\n",
    "print(\"\\033[0m\")  # stop bold and red\n",
    "print(\"Overall Accuracy: \", round(overall_accuracy_kmeans, 2))\n",
    "print(\"F1 score: \\t\", round(f1score_kmeans, 2))\n",
    "print(\"Producer's Accuracy: \", round(urban_precision_kmeans, 2))\n",
    "print(\n",
    "    \"User's Accuracy: \",\n",
    "    round(urban_recall_kmeans, 2),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `dstack` calls provide the `imshow` calls with RGB array inputs. \n",
    "For the plotted image, the first channel (red) is the actual (ground truth, ESA Worldcover) values, and both the second and third channels (green, blue) are the predicted values (green + blue = cyan)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "plt.imshow(\n",
    "    np.dstack(\n",
    "        (\n",
    "            built_up.data.astype(float),\n",
    "            clustering_predicted_ds_july.data.astype(float),\n",
    "            clustering_predicted_ds_july.data.astype(float),\n",
    "        )\n",
    "    )\n",
    ")\n",
    "plt.legend(\n",
    "    [Patch(facecolor=\"cyan\"), Patch(facecolor=\"red\"), Patch(facecolor=\"white\")],\n",
    "    [\"False Positive\", \"False Negative\", \"True Positive\"],\n",
    "    loc=\"lower left\",\n",
    "    fontsize=10,\n",
    ")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Urban Area Mapping Clustering Results\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the built up land cover from the ESA worldcover dataset.\n",
    "esa_urban_class = 50\n",
    "\n",
    "built_up = ds_esa[\"classification\"] == esa_urban_class\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(14, 6), sharey=True)\n",
    "built_up.plot.imshow(ax=ax[0], add_colorbar=False)\n",
    "clustering_predicted_ds_september.plot.imshow(ax=ax[1], add_colorbar=False)\n",
    "ax[1].set_title(\"K-means Clustering Predicted image-September\")\n",
    "ax[0].set_title(\"ESA WorldCover Built up Landcover\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics for the Kmeans Clustering.\n",
    "y_true = sklearn_flatten(built_up)\n",
    "y_pred_kmeans = sklearn_flatten(clustering_predicted_ds_september)\n",
    "\n",
    "# Producer's Accuracies.\n",
    "precision_kmeans = precision_score(y_true, y_pred_kmeans, labels=[0, 1], average=None)\n",
    "urban_precision_kmeans = precision_kmeans[1] * 100\n",
    "\n",
    "# User's Accuracies.\n",
    "recall_kmeans = recall_score(y_true, y_pred_kmeans, labels=[0, 1], average=None)\n",
    "urban_recall_kmeans = recall_kmeans[1] * 100\n",
    "\n",
    "# Overall Accuracy.\n",
    "accuracy_kmeans = accuracy_score(y_true, y_pred_kmeans, normalize=True)\n",
    "overall_accuracy_kmeans = accuracy_kmeans * 100\n",
    "\n",
    "# F1 score.\n",
    "f1score_kmeans = f1_score(y_true, y_pred_kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"\\033[1m\" + \"\\033[91m\" + \"Urban Area Mapping using k-means clustering Results September\"\n",
    ")  # bold print and red\n",
    "print(\"\\033[0m\")  # stop bold and red\n",
    "print(\"Overall Accuracy: \", round(overall_accuracy_kmeans, 2))\n",
    "print(\"F1 score: \\t\", round(f1score_kmeans, 2))\n",
    "print(\"Producer's Accuracy: \", round(urban_precision_kmeans, 2))\n",
    "print(\n",
    "    \"User's Accuracy: \",\n",
    "    round(urban_recall_kmeans, 2),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "plt.imshow(\n",
    "    np.dstack(\n",
    "        (\n",
    "            built_up.data.astype(float),\n",
    "            clustering_predicted_ds_september.data.astype(float),\n",
    "            clustering_predicted_ds_september.data.astype(float),\n",
    "        )\n",
    "    )\n",
    ")\n",
    "plt.legend(\n",
    "    [Patch(facecolor=\"cyan\"), Patch(facecolor=\"red\"), Patch(facecolor=\"white\")],\n",
    "    [\"False Positive\", \"False Negative\", \"True Positive\"],\n",
    "    loc=\"lower left\",\n",
    "    fontsize=10,\n",
    ")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Urban Area Mapping Clustering Results\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(14, 6), sharey=True)\n",
    "clustering_predicted_ds_july.plot.imshow(ax=ax[0], add_colorbar=False,)\n",
    "clustering_predicted_ds_september.plot.imshow(ax=ax[1], add_colorbar=False)\n",
    "\n",
    "ax[0].set_title(\"July\")\n",
    "ax[1].set_title(\"September\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "\n",
    "built_up.where(built_up == True\n",
    "                                  ).plot.imshow(cmap=ListedColormap(['Red']),add_colorbar=False, ax=ax)\n",
    "\n",
    "\n",
    "permanent_water.plot.imshow(\n",
    "    cmap=ListedColormap([stable_color]),\n",
    "    add_colorbar=False,\n",
    "    add_labels=False,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "water_appeared.plot.imshow(\n",
    "    cmap=ListedColormap([water_appeared_color]),\n",
    "    add_colorbar=False,\n",
    "    add_labels=False,\n",
    "    ax=ax,\n",
    ")\n",
    "water_disappeared.plot.imshow(\n",
    "    cmap=ListedColormap([water_disappeared_color]),\n",
    "    add_colorbar=False,\n",
    "    add_labels=False,\n",
    "    ax=ax,\n",
    ")\n",
    "crop_land.where(crop_land == True\n",
    "               ).plot.imshow(cmap=ListedColormap(['Green']),\n",
    "                                       add_colorbar=False,\n",
    "                                       add_labels=False,\n",
    "                                       ax=ax)\n",
    "plt.legend(\n",
    "    [\n",
    "        Patch(facecolor='Red'),\n",
    "        Patch(facecolor='Green'),\n",
    "        Patch(facecolor=stable_color),\n",
    "        Patch(facecolor=water_disappeared_color),\n",
    "        Patch(facecolor=water_appeared_color),\n",
    "    ],\n",
    "    [\n",
    "        f\"Urban\",\n",
    "        f\"Vegetation\",\n",
    "        f\"Water to Water\",\n",
    "        f\"Water to No Water\",\n",
    "        f\"No Water to Water\",\n",
    "    ],\n",
    "    loc=\"lower left\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flood Risk Assessment using Elevation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the dem 30 m product\n",
    "ds_elevation = dc.load(product=\"dem_cop_30\",measurements = \"elevation\", **query).squeeze()\n",
    "print(ds_elevation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_elevation.elevation.plot(cmap='ocean',add_colorbar=False, size=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_high = ds_elevation.assign(high=xr.where(ds_elevation.elevation <= 50, 1, 0))\n",
    "ds_medium = ds_elevation.assign(high=xr.where(ds_elevation.elevation <= 100, 1, 0))\n",
    "\n",
    "ds_h =  ds_high.where((ds_high.high == 1)).compute()\n",
    "ds_m =  ds_medium.where((ds_medium.high == 1) & (ds_high.high == 0)).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the flood prone built up areas and cropland.\n",
    "h_affected_urban = built_up.where((built_up == True) & (ds_h.high == 1))\n",
    "h_affected_vegetation = crop_land.where((crop_land == True) & (ds_h.high == 1))\n",
    "\n",
    "m_affected_urban = built_up.where((built_up == True) & (ds_m.high == 1))\n",
    "m_affected_vegetation = crop_land.where((crop_land == True) & (ds_m.high == 1))\n",
    "\n",
    "unaffected_urban = built_up.where((built_up == True) & (np.isnan(ds_h.high)) & (np.isnan(ds_m.high)))\n",
    "unaffected_vegetation = crop_land.where((crop_land == True) & (np.isnan(ds_h.high)) & (np.isnan(ds_m.high)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "\n",
    "h_affected_urban.plot.imshow(cmap=ListedColormap(['#ff0000']), add_colorbar=False, ax=ax)\n",
    "h_affected_vegetation.plot.imshow(cmap=ListedColormap(['#ffe100']), add_colorbar=False, ax=ax)\n",
    "\n",
    "m_affected_urban.plot.imshow(cmap=ListedColormap(['#6b0d60']), add_colorbar=False, ax=ax)\n",
    "m_affected_vegetation.plot.imshow(cmap=ListedColormap(['#44fc9a']), add_colorbar=False, ax=ax)\n",
    "\n",
    "unaffected_urban.plot.imshow(cmap=ListedColormap(['Brown']), add_colorbar=False, ax=ax)\n",
    "unaffected_vegetation.plot.imshow(cmap=ListedColormap(['Green']), add_colorbar=False, ax=ax)\n",
    "\n",
    "\n",
    "plt.legend(\n",
    "    [\n",
    "        Patch(facecolor=\"#ff0000\"),\n",
    "        Patch(facecolor=\"#ffe100\"),\n",
    "        Patch(facecolor=\"#6b0d60\"),\n",
    "        Patch(facecolor=\"#44fc9a\"),\n",
    "        Patch(facecolor=\"Brown\"),\n",
    "        Patch(facecolor=\"Green\")\n",
    "    ],\n",
    "    [\n",
    "        \"High Flood prone built up areas\",\n",
    "        \"High Flood prone cropland\",\n",
    "        \"Medium Flood prone built up areas\",\n",
    "        \"Meduim Flood prone cropland\",\n",
    "        \"Unaffected Built up area\",\n",
    "        \"Unaffected cropland\",\n",
    "        \n",
    "    ],\n",
    "    loc=\"lower left\",\n",
    ")\n",
    "\n",
    "plt.title(\"Flood prone built up areas and cropland\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_length = query[\"resolution\"][1]  # in metres\n",
    "m_per_km = 1000  # conversion from metres to kilometres\n",
    "area_per_pixel = pixel_length**2 / m_per_km**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the areas of the flood prone built up areas and cropland.\n",
    "h_area_affected_urban = np.float((h_affected_urban.sum(dim=['x', 'y']) * area_per_pixel).data)\n",
    "h_area_affected_cropland = np.float((h_affected_vegetation.sum(dim=['x', 'y']) * area_per_pixel).data)\n",
    "\n",
    "m_area_affected_urban = np.float((m_affected_urban.sum(dim=['x', 'y']) * area_per_pixel).data)\n",
    "m_area_affected_cropland = np.float((m_affected_vegetation.sum(dim=['x', 'y']) * area_per_pixel).data)\n",
    "\n",
    "un_area_affected_urban = np.float((unaffected_urban.sum(dim=['x', 'y']) * area_per_pixel).data)\n",
    "un_area_affected_cropland = np.float((unaffected_vegetation.sum(dim=['x', 'y']) * area_per_pixel).data)\n",
    "\n",
    "print(f'Built up area highly prone to flooding: {round(h_area_affected_urban, 3)} kmsq')\n",
    "print(f'Cropland  area highly prone to flooding: {round(h_area_affected_cropland, 3)} kmsq')\n",
    "print(f'Built up area meduim prone to flooding: {round(m_area_affected_urban, 3)} kmsq')\n",
    "print(f'Cropland  area meduim prone to flooding: {round(m_area_affected_cropland, 3)} kmsq')\n",
    "print(f'Built up area unaffected to flooding: {round(un_area_affected_urban, 3)} kmsq')\n",
    "print(f'Cropland area unaffected to flooding: {round(un_area_affected_cropland, 3)} kmsq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_crop_land = h_area_affected_cropland + m_area_affected_cropland + un_area_affected_cropland\n",
    "total_urban = un_area_affected_urban + m_area_affected_urban + h_area_affected_urban\n",
    "\n",
    "print(f'Total Crop Land: {round(total_crop_land, 3)} kmsq')\n",
    "print(f'Total Urban: {round(total_urban, 3)} kmsq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "plt.bar(('Total Urban','High Flood Urban', 'Medium Flood Urban', 'Unaffected Flood Urban'),(\n",
    "    total_urban, h_area_affected_urban, m_area_affected_urban, un_area_affected_urban),facecolor='red')\n",
    "plt.ylabel('KmSq')\n",
    "plt.title('Bar Graph Showing Total and Affected Urban Area')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(('Total Crop Land','Higly Flood', 'Meduim Flood', 'Unaffected'),(\n",
    "    total_crop_land, h_area_affected_cropland, m_area_affected_cropland, un_area_affected_cropland),facecolor='Green')\n",
    "plt.ylabel('KmSq')\n",
    "plt.title('Bar Graph Showing Total and Affected Crop Land')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Additional information\n",
    "\n",
    "**License:** The code in this notebook is licensed under the [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0). \n",
    "Digital Earth Africa data is licensed under the [Creative Commons by Attribution 4.0](https://creativecommons.org/licenses/by/4.0/) license.\n",
    "\n",
    "**Contact:** If you need assistance, please post a question on the [Open Data Cube Slack channel](http://slack.opendatacube.org/) or on the [GIS Stack Exchange](https://gis.stackexchange.com/questions/ask?tags=open-data-cube) using the `open-data-cube` tag (you can view previously asked questions [here](https://gis.stackexchange.com/questions/tagged/open-data-cube)).\n",
    "If you would like to report an issue with this notebook, you can file one on [Github](https://github.com/digitalearthafrica/deafrica-sandbox-notebooks).\n",
    "\n",
    "**Compatible datacube version:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datacube.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Last Tested:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "datetime.today().strftime(\"%Y-%m-%d\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "a9018f63b6ed3ecd0e1934aa225a6796f97868e31467124cf4e25310bb348c78"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
